2025-09-13 17:18:03,362 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:18:03,362 - INFO - Language: English -> Spanish
2025-09-13 17:18:03,363 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:18:03,369 - INFO - Step 1: Extracting document content...
2025-09-13 17:18:03,706 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:18:03,706 - INFO - Step 2: Translating content...
2025-09-13 17:18:03,707 - INFO - Translating 129 paragraphs...
2025-09-13 17:18:03,707 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:18:03,712 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:05,892 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 503 Service Unavailable"
2025-09-13 17:18:06,155 - ERROR - Translation error: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}

2025-09-13 17:18:06,156 - ERROR - Failed text: Chapter 2...
2025-09-13 17:18:06,157 - INFO - Progress: 2/131 - Translating paragraph 1
2025-09-13 17:18:06,158 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:06,560 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 503 Service Unavailable"
2025-09-13 17:18:06,582 - ERROR - Translation error: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}

2025-09-13 17:18:06,583 - ERROR - Failed text: Verses 64-92...
2025-09-13 17:18:06,583 - INFO - Progress: 3/131 - Translating paragraph 2
2025-09-13 17:18:06,584 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:16,985 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:16,990 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:16,995 - INFO - Progress: 4/131 - Translating paragraph 4
2025-09-13 17:18:16,996 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:19,007 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:19,009 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:19,011 - INFO - Progress: 5/131 - Translating paragraph 5
2025-09-13 17:18:19,012 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:21,327 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:21,330 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:21,332 - INFO - Progress: 6/131 - Translating paragraph 6
2025-09-13 17:18:21,333 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:21,903 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:21,906 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:21,908 - INFO - Progress: 7/131 - Translating paragraph 7
2025-09-13 17:18:21,909 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:25,362 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:25,366 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:25,367 - INFO - Progress: 8/131 - Translating paragraph 8
2025-09-13 17:18:25,372 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:27,113 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:27,117 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:27,118 - INFO - Progress: 9/131 - Translating paragraph 10
2025-09-13 17:18:27,122 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:29,484 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:29,487 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:29,490 - INFO - Progress: 10/131 - Translating paragraph 11
2025-09-13 17:18:29,494 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:31,512 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:31,515 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:31,517 - INFO - Progress: 11/131 - Translating paragraph 12
2025-09-13 17:18:31,519 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:32,949 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:32,952 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:32,955 - INFO - Progress: 12/131 - Translating paragraph 13
2025-09-13 17:18:32,957 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:34,930 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:34,933 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:34,936 - INFO - Progress: 13/131 - Translating paragraph 14
2025-09-13 17:18:34,938 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:38,283 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:38,286 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:38,288 - INFO - Progress: 14/131 - Translating paragraph 16
2025-09-13 17:18:38,291 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:42,858 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:42,861 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:42,863 - INFO - Progress: 15/131 - Translating paragraph 17
2025-09-13 17:18:42,865 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:45,823 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:45,827 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:45,830 - INFO - Progress: 16/131 - Translating paragraph 18
2025-09-13 17:18:45,834 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:47,254 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:47,257 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:47,259 - INFO - Progress: 17/131 - Translating paragraph 19
2025-09-13 17:18:47,264 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:47,588 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:47,623 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "12s"
      }
    ]
  }
}

2025-09-13 17:18:47,624 - ERROR - Failed text: Apparently, R. Yosi, the author of the story, is the Tanna who lived in the second century CE, but i...
2025-09-13 17:18:47,624 - INFO - Progress: 18/131 - Translating paragraph 20
2025-09-13 17:18:47,626 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:51,079 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:18:51,082 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:18:51,085 - INFO - Progress: 19/131 - Translating paragraph 21
2025-09-13 17:18:51,087 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:51,414 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:51,442 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "8s"
      }
    ]
  }
}

2025-09-13 17:18:51,443 - ERROR - Failed text: Commentary on Chapter 2:...
2025-09-13 17:18:51,443 - INFO - Progress: 20/131 - Translating paragraph 22
2025-09-13 17:18:51,445 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:52,722 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:52,754 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}

2025-09-13 17:18:52,755 - ERROR - Failed text: (64) After these true things – A  sentence that connects in the dimension of time: the second chapte...
2025-09-13 17:18:52,755 - INFO - Progress: 21/131 - Translating paragraph 23
2025-09-13 17:18:52,757 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:53,081 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:53,110 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "6s"
      }
    ]
  }
}

2025-09-13 17:18:53,111 - ERROR - Failed text: I had a divine vision saying: – usual formulation in the words of the prophets is (e.g., Ezekiel 29:...
2025-09-13 17:18:53,112 - INFO - Progress: 22/131 - Translating paragraph 24
2025-09-13 17:18:53,113 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:54,457 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:54,485 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-09-13 17:18:54,487 - ERROR - Failed text: (65) ‘Set thy face – The seer is commanded to turn his face towards the audience in order to increas...
2025-09-13 17:18:54,488 - INFO - Progress: 23/131 - Translating paragraph 25
2025-09-13 17:18:54,490 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:54,817 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:54,849 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-09-13 17:18:54,850 - ERROR - Failed text: eastward, northward, southward and westward — turn your face toward the east, then toward the north,...
2025-09-13 17:18:54,851 - INFO - Progress: 24/131 - Translating paragraph 26
2025-09-13 17:18:54,853 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:56,123 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:56,155 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-09-13 17:18:56,156 - ERROR - Failed text: (66) And whistle with your mouth as a bird whistles to its chicks – the call of the seer is similar ...
2025-09-13 17:18:56,157 - INFO - Progress: 25/131 - Translating paragraph 27
2025-09-13 17:18:56,159 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:56,485 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:56,514 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-09-13 17:18:56,515 - ERROR - Failed text: and say: Four corners of the earth – the four directions mentioned in the previous verse are well kn...
2025-09-13 17:18:56,516 - INFO - Progress: 26/131 - Translating paragraph 28
2025-09-13 17:18:56,518 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:57,767 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:57,795 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-09-13 17:18:57,796 - ERROR - Failed text: listen to the word of the Lord – The prophets made a similar address to the people as a declaration ...
2025-09-13 17:18:57,796 - INFO - Progress: 27/131 - Translating paragraph 29
2025-09-13 17:18:57,798 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:58,131 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:58,160 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-09-13 17:18:58,161 - ERROR - Failed text: (67) Thus saith the Lord – the seer informs his listeners, whether orally or in writing, that he is ...
2025-09-13 17:18:58,162 - INFO - Progress: 28/131 - Translating paragraph 30
2025-09-13 17:18:58,165 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:59,406 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:59,437 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-09-13 17:18:59,442 - ERROR - Failed text: who sits and dwells over the cherubs – The Lord’s appellation as He ‘Who sits on the Cherubs’ appear...
2025-09-13 17:18:59,443 - INFO - Progress: 29/131 - Translating paragraph 31
2025-09-13 17:18:59,446 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:18:59,794 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:18:59,844 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "59s"
      }
    ]
  }
}

2025-09-13 17:18:59,845 - ERROR - Failed text: Give, give, give, take out, take out, take out – The seer intensifies his declaration by tripling ea...
2025-09-13 17:18:59,846 - INFO - Progress: 30/131 - Translating paragraph 32
2025-09-13 17:18:59,848 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:01,058 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:01,082 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "58s"
      }
    ]
  }
}

2025-09-13 17:19:01,082 - ERROR - Failed text: my seed that I have sown in you – Israel is likened to the seed (wheat) that God sowed throughout th...
2025-09-13 17:19:01,083 - INFO - Progress: 31/131 - Translating paragraph 33
2025-09-13 17:19:01,086 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:01,458 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:01,481 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "58s"
      }
    ]
  }
}

2025-09-13 17:19:01,482 - ERROR - Failed text: for the time for the seed has come – the reason for the command: the time of gathering the seed has ...
2025-09-13 17:19:01,482 - INFO - Progress: 32/131 - Translating paragraph 34
2025-09-13 17:19:01,483 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:02,748 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:02,772 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-09-13 17:19:02,773 - ERROR - Failed text: (68) For yet a little while (above, 55)....
2025-09-13 17:19:02,774 - INFO - Progress: 33/131 - Translating paragraph 35
2025-09-13 17:19:02,775 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:03,112 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:03,134 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "56s"
      }
    ]
  }
}

2025-09-13 17:19:03,134 - ERROR - Failed text: I shall collect my seed on my threshing-floor – it reads: 'And I gathered my seed in my granary’. Is...
2025-09-13 17:19:03,135 - INFO - Progress: 34/131 - Translating paragraph 36
2025-09-13 17:19:03,136 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:04,381 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:04,404 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "55s"
      }
    ]
  }
}

2025-09-13 17:19:04,405 - ERROR - Failed text: (69) And the threshing-floor will be holy – it reads: ‘And the granary shall be holy,’ meaning the L...
2025-09-13 17:19:04,406 - INFO - Progress: 35/131 - Translating paragraph 37
2025-09-13 17:19:04,407 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:04,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:04,847 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "54s"
      }
    ]
  }
}

2025-09-13 17:19:04,848 - ERROR - Failed text: an impure seed will not be found in it – the Lord shall bring into His granary, into the Land of Isr...
2025-09-13 17:19:04,849 - INFO - Progress: 36/131 - Translating paragraph 38
2025-09-13 17:19:04,851 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:06,076 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:06,100 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "53s"
      }
    ]
  }
}

2025-09-13 17:19:06,101 - ERROR - Failed text: (70) For before those days – a phrase describing a time-period found in Zechariah 8:10, in contrast ...
2025-09-13 17:19:06,102 - INFO - Progress: 37/131 - Translating paragraph 39
2025-09-13 17:19:06,105 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:14,588 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:14,591 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:14,592 - INFO - Progress: 38/131 - Translating paragraph 40
2025-09-13 17:19:14,594 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:17,644 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:17,647 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:17,649 - INFO - Progress: 39/131 - Translating paragraph 41
2025-09-13 17:19:17,652 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:18,614 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:18,616 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:18,618 - INFO - Progress: 40/131 - Translating paragraph 42
2025-09-13 17:19:18,621 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:20,461 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:20,464 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:20,466 - INFO - Progress: 41/131 - Translating paragraph 43
2025-09-13 17:19:20,468 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:22,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:22,819 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:22,820 - INFO - Progress: 42/131 - Translating paragraph 44
2025-09-13 17:19:22,824 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:23,733 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:23,736 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:23,738 - INFO - Progress: 43/131 - Translating paragraph 45
2025-09-13 17:19:23,741 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:25,010 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:25,014 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:25,016 - INFO - Progress: 44/131 - Translating paragraph 46
2025-09-13 17:19:25,017 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:26,562 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:26,565 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:26,567 - INFO - Progress: 45/131 - Translating paragraph 47
2025-09-13 17:19:26,571 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:27,371 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:27,373 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:27,374 - INFO - Progress: 46/131 - Translating paragraph 48
2025-09-13 17:19:27,375 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:29,402 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:29,405 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:29,407 - INFO - Progress: 47/131 - Translating paragraph 49
2025-09-13 17:19:29,408 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:30,448 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:30,451 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:30,452 - INFO - Progress: 48/131 - Translating paragraph 50
2025-09-13 17:19:30,456 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:31,479 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:31,481 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:31,484 - INFO - Progress: 49/131 - Translating paragraph 51
2025-09-13 17:19:31,486 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:33,258 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:33,261 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:33,262 - INFO - Progress: 50/131 - Translating paragraph 52
2025-09-13 17:19:33,263 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:34,601 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:34,603 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:34,605 - INFO - Progress: 51/131 - Translating paragraph 53
2025-09-13 17:19:34,608 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:36,936 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:36,939 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:36,942 - INFO - Progress: 52/131 - Translating paragraph 54
2025-09-13 17:19:36,947 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:37,739 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:19:37,742 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:19:37,744 - INFO - Progress: 53/131 - Translating paragraph 55
2025-09-13 17:19:37,749 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:38,634 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 503 Service Unavailable"
2025-09-13 17:19:38,661 - ERROR - Translation error: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}

2025-09-13 17:19:38,662 - ERROR - Failed text: one God – The current situation is (Deuteronomy 6:4; below, 183, 277): ‘Hear, O Israel, the Lord is ...
2025-09-13 17:19:38,662 - INFO - Progress: 54/131 - Translating paragraph 56
2025-09-13 17:19:38,663 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:39,403 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:39,431 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "20s"
      }
    ]
  }
}

2025-09-13 17:19:39,432 - ERROR - Failed text: one covenant – that is, there will not be different covenants between God and the nations...
2025-09-13 17:19:39,433 - INFO - Progress: 55/131 - Translating paragraph 57
2025-09-13 17:19:39,434 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:40,356 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 503 Service Unavailable"
2025-09-13 17:19:40,382 - ERROR - Translation error: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {
  "error": {
    "code": 503,
    "message": "The model is overloaded. Please try again later.",
    "status": "UNAVAILABLE"
  }
}

2025-09-13 17:19:40,382 - ERROR - Failed text: one law –  the law of Israel (and not many laws, neither a god and his law nor a nation and its law)...
2025-09-13 17:19:40,383 - INFO - Progress: 56/131 - Translating paragraph 58
2025-09-13 17:19:40,384 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:41,049 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:41,068 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "18s"
      }
    ]
  }
}

2025-09-13 17:19:41,069 - ERROR - Failed text: one language – all the nations will speak one language, and these words reflect (or are supported by...
2025-09-13 17:19:41,069 - INFO - Progress: 57/131 - Translating paragraph 59
2025-09-13 17:19:41,070 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:42,000 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:42,023 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "17s"
      }
    ]
  }
}

2025-09-13 17:19:42,024 - ERROR - Failed text: for all shall speak the Jews’ language, the holy language – in the end times, after all the nations ...
2025-09-13 17:19:42,025 - INFO - Progress: 58/131 - Translating paragraph 60
2025-09-13 17:19:42,025 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:42,688 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:42,710 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "17s"
      }
    ]
  }
}

2025-09-13 17:19:42,711 - ERROR - Failed text: (77) Happy art thou, O Israel, who is like unto thee? A people saved by the Lord – this is a blessin...
2025-09-13 17:19:42,712 - INFO - Progress: 59/131 - Translating paragraph 61
2025-09-13 17:19:42,713 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:52,050 - DEBUG - Verbose logging enabled
2025-09-13 17:19:52,051 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:19:52,052 - INFO - Language: English -> Spanish
2025-09-13 17:19:52,052 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:19:52,052 - INFO - Step 1: Extracting document content...
2025-09-13 17:19:52,382 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:19:52,386 - INFO - Step 2: Translating content...
2025-09-13 17:19:52,387 - INFO - Translating 129 paragraphs...
2025-09-13 17:19:52,387 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:19:52,388 - DEBUG - 

2025-09-13 17:19:52,388 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:52,389 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=6)[0m
2025-09-13 17:19:52,390 - DEBUG - 

2025-09-13 17:19:52,390 - DEBUG - self.optional_params: {}
2025-09-13 17:19:52,390 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:52,396 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:52,397 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:52,397 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 6, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:52,398 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:19:52,398 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 6}
2025-09-13 17:19:52,398 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:19:52,399 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:52,402 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:52,403 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 6}}'
[0m

2025-09-13 17:19:52,789 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-09-13 17:19:52,827 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002771EDD42D0>
2025-09-13 17:19:52,827 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002771ED78A70> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-09-13 17:19:52,870 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002771ED2E8B0>
2025-09-13 17:19:52,871 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:52,872 - DEBUG - send_request_headers.complete
2025-09-13 17:19:52,872 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:52,872 - DEBUG - send_request_body.complete
2025-09-13 17:19:52,873 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:54,466 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1556'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:54,469 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:54,470 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:54,471 - DEBUG - receive_response_body.complete
2025-09-13 17:19:54,471 - DEBUG - response_closed.started
2025-09-13 17:19:54,472 - DEBUG - response_closed.complete
2025-09-13 17:19:54,474 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:54,495 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:54,503 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "5s"
      }
    ]
  }
}

2025-09-13 17:19:54,503 - ERROR - Failed text: Chapter 2...
2025-09-13 17:19:54,503 - INFO - Progress: 2/131 - Translating paragraph 1
2025-09-13 17:19:54,504 - DEBUG - 

2025-09-13 17:19:54,504 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:54,505 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=6)[0m
2025-09-13 17:19:54,505 - DEBUG - 

2025-09-13 17:19:54,506 - DEBUG - self.optional_params: {}
2025-09-13 17:19:54,507 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:54,508 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:54,509 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:54,509 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 6, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:54,510 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:19:54,510 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 6}
2025-09-13 17:19:54,511 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:19:54,512 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:54,512 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:54,513 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 6}}'
[0m

2025-09-13 17:19:54,514 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:54,514 - DEBUG - send_request_headers.complete
2025-09-13 17:19:54,514 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:54,515 - DEBUG - send_request_body.complete
2025-09-13 17:19:54,515 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:54,830 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=278'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:54,831 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:54,831 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:54,832 - DEBUG - receive_response_body.complete
2025-09-13 17:19:54,833 - DEBUG - response_closed.started
2025-09-13 17:19:54,834 - DEBUG - response_closed.complete
2025-09-13 17:19:54,836 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:54,859 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:54,867 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "4s"
      }
    ]
  }
}

2025-09-13 17:19:54,867 - ERROR - Failed text: Verses 64-92...
2025-09-13 17:19:54,867 - INFO - Progress: 3/131 - Translating paragraph 2
2025-09-13 17:19:54,869 - DEBUG - 

2025-09-13 17:19:54,870 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:54,870 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=30)[0m
2025-09-13 17:19:54,870 - DEBUG - 

2025-09-13 17:19:54,871 - DEBUG - self.optional_params: {}
2025-09-13 17:19:54,872 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:54,873 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:54,874 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:54,875 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 30, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:54,875 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 30}
2025-09-13 17:19:54,876 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 30}
2025-09-13 17:19:54,876 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 30}
2025-09-13 17:19:54,876 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:54,877 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:54,877 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 30}}'
[0m

2025-09-13 17:19:54,878 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:54,879 - DEBUG - send_request_headers.complete
2025-09-13 17:19:54,879 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:54,879 - DEBUG - send_request_body.complete
2025-09-13 17:19:54,879 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:56,159 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1243'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:56,159 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:56,159 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:56,160 - DEBUG - receive_response_body.complete
2025-09-13 17:19:56,160 - DEBUG - response_closed.started
2025-09-13 17:19:56,160 - DEBUG - response_closed.complete
2025-09-13 17:19:56,162 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:56,168 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:56,173 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-09-13 17:19:56,174 - ERROR - Failed text: The Second Vision: A Vision of the End of Days...
2025-09-13 17:19:56,174 - INFO - Progress: 4/131 - Translating paragraph 4
2025-09-13 17:19:56,175 - DEBUG - 

2025-09-13 17:19:56,175 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:56,175 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=12)[0m
2025-09-13 17:19:56,176 - DEBUG - 

2025-09-13 17:19:56,176 - DEBUG - self.optional_params: {}
2025-09-13 17:19:56,177 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:56,177 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:56,178 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:56,178 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 12, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:56,178 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:19:56,179 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 12}
2025-09-13 17:19:56,179 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:19:56,180 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:56,180 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:56,181 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 12}}'
[0m

2025-09-13 17:19:56,182 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:56,182 - DEBUG - send_request_headers.complete
2025-09-13 17:19:56,183 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:56,183 - DEBUG - send_request_body.complete
2025-09-13 17:19:56,183 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:56,504 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=284'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:56,505 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:56,506 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:56,507 - DEBUG - receive_response_body.complete
2025-09-13 17:19:56,508 - DEBUG - response_closed.started
2025-09-13 17:19:56,509 - DEBUG - response_closed.complete
2025-09-13 17:19:56,511 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:56,523 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:56,534 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "3s"
      }
    ]
  }
}

2025-09-13 17:19:56,535 - ERROR - Failed text: Synopsis of Chapter 2:...
2025-09-13 17:19:56,537 - INFO - Progress: 5/131 - Translating paragraph 5
2025-09-13 17:19:56,537 - DEBUG - 

2025-09-13 17:19:56,538 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:56,540 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=438)[0m
2025-09-13 17:19:56,541 - DEBUG - 

2025-09-13 17:19:56,542 - DEBUG - self.optional_params: {}
2025-09-13 17:19:56,543 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:56,544 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:56,545 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:56,546 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 438, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:56,547 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 438}
2025-09-13 17:19:56,547 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 438}
2025-09-13 17:19:56,548 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 438}
2025-09-13 17:19:56,548 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:56,549 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:56,550 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 438}}'
[0m

2025-09-13 17:19:56,550 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:56,551 - DEBUG - send_request_headers.complete
2025-09-13 17:19:56,552 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:56,553 - DEBUG - send_request_body.complete
2025-09-13 17:19:56,553 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:57,797 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1208'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:57,798 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:57,798 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:57,799 - DEBUG - receive_response_body.complete
2025-09-13 17:19:57,799 - DEBUG - response_closed.started
2025-09-13 17:19:57,799 - DEBUG - response_closed.complete
2025-09-13 17:19:57,801 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:57,810 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:57,815 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-09-13 17:19:57,816 - ERROR - Failed text: Gad, in his vision, saw what would occur to the people of Israel and to the nations of the world at ...
2025-09-13 17:19:57,817 - INFO - Progress: 6/131 - Translating paragraph 6
2025-09-13 17:19:57,817 - DEBUG - 

2025-09-13 17:19:57,817 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:57,817 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=12)[0m
2025-09-13 17:19:57,818 - DEBUG - 

2025-09-13 17:19:57,819 - DEBUG - self.optional_params: {}
2025-09-13 17:19:57,819 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:57,821 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:57,821 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:57,822 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 12, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:57,823 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:19:57,825 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 12}
2025-09-13 17:19:57,827 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:19:57,828 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:57,829 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:57,829 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 12}}'
[0m

2025-09-13 17:19:57,831 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:57,832 - DEBUG - send_request_headers.complete
2025-09-13 17:19:57,832 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:57,833 - DEBUG - send_request_body.complete
2025-09-13 17:19:57,833 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:58,173 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=304'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:58,174 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:58,174 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:58,175 - DEBUG - receive_response_body.complete
2025-09-13 17:19:58,176 - DEBUG - response_closed.started
2025-09-13 17:19:58,176 - DEBUG - response_closed.complete
2025-09-13 17:19:58,178 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:58,189 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:58,201 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "1s"
      }
    ]
  }
}

2025-09-13 17:19:58,202 - ERROR - Failed text: Introduction to Chapter 2:...
2025-09-13 17:19:58,202 - INFO - Progress: 7/131 - Translating paragraph 7
2025-09-13 17:19:58,203 - DEBUG - 

2025-09-13 17:19:58,204 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:58,205 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=648)[0m
2025-09-13 17:19:58,206 - DEBUG - 

2025-09-13 17:19:58,208 - DEBUG - self.optional_params: {}
2025-09-13 17:19:58,209 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:58,211 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:58,212 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:58,212 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 648, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:58,213 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 648}
2025-09-13 17:19:58,214 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 648}
2025-09-13 17:19:58,215 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 648}
2025-09-13 17:19:58,215 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:58,216 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:58,216 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 648}}'
[0m

2025-09-13 17:19:58,218 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:58,219 - DEBUG - send_request_headers.complete
2025-09-13 17:19:58,219 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:58,219 - DEBUG - send_request_body.complete
2025-09-13 17:19:58,220 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:59,457 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:49:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1201'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:59,458 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:59,458 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:59,459 - DEBUG - receive_response_body.complete
2025-09-13 17:19:59,459 - DEBUG - response_closed.started
2025-09-13 17:19:59,460 - DEBUG - response_closed.complete
2025-09-13 17:19:59,461 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:59,470 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:59,477 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-09-13 17:19:59,478 - ERROR - Failed text: Chapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and t...
2025-09-13 17:19:59,479 - INFO - Progress: 8/131 - Translating paragraph 8
2025-09-13 17:19:59,479 - DEBUG - 

2025-09-13 17:19:59,480 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:59,480 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=456)[0m
2025-09-13 17:19:59,481 - DEBUG - 

2025-09-13 17:19:59,481 - DEBUG - self.optional_params: {}
2025-09-13 17:19:59,482 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:59,483 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:59,483 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:59,484 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 456, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:59,485 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 456}
2025-09-13 17:19:59,486 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 456}
2025-09-13 17:19:59,487 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 456}
2025-09-13 17:19:59,488 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:59,490 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:59,491 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 456}}'
[0m

2025-09-13 17:19:59,493 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:59,493 - DEBUG - send_request_headers.complete
2025-09-13 17:19:59,493 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:59,494 - DEBUG - send_request_body.complete
2025-09-13 17:19:59,494 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:19:59,815 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:50:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=285'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:19:59,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:19:59,817 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:19:59,817 - DEBUG - receive_response_body.complete
2025-09-13 17:19:59,817 - DEBUG - response_closed.started
2025-09-13 17:19:59,817 - DEBUG - response_closed.complete
2025-09-13 17:19:59,819 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:19:59,829 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:19:59,834 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "59s"
      }
    ]
  }
}

2025-09-13 17:19:59,835 - ERROR - Failed text: In several ways, as a pair of chapters that complement each other, the second vision completes the v...
2025-09-13 17:19:59,835 - INFO - Progress: 9/131 - Translating paragraph 10
2025-09-13 17:19:59,835 - DEBUG - 

2025-09-13 17:19:59,835 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:19:59,836 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=564)[0m
2025-09-13 17:19:59,836 - DEBUG - 

2025-09-13 17:19:59,837 - DEBUG - self.optional_params: {}
2025-09-13 17:19:59,838 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:19:59,840 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:19:59,842 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:19:59,842 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 564, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:19:59,843 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 564}
2025-09-13 17:19:59,844 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 564}
2025-09-13 17:19:59,845 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 564}
2025-09-13 17:19:59,845 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:59,846 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:19:59,846 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 564}}'
[0m

2025-09-13 17:19:59,847 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:19:59,847 - DEBUG - send_request_headers.complete
2025-09-13 17:19:59,848 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:19:59,848 - DEBUG - send_request_body.complete
2025-09-13 17:19:59,848 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:20:01,104 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:50:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:20:01,104 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:20:01,105 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:20:01,105 - DEBUG - receive_response_body.complete
2025-09-13 17:20:01,105 - DEBUG - response_closed.started
2025-09-13 17:20:01,106 - DEBUG - response_closed.complete
2025-09-13 17:20:01,107 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:20:01,116 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:20:01,126 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerMinutePerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "15"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "58s"
      }
    ]
  }
}

2025-09-13 17:20:01,127 - ERROR - Failed text: The first matter to emerge in the end of days is to be the gathering of Israel to their land, an ide...
2025-09-13 17:20:01,128 - INFO - Progress: 10/131 - Translating paragraph 11
2025-09-13 17:20:01,128 - DEBUG - 

2025-09-13 17:20:01,129 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:20:01,129 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': "Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe wheat and the straw argued with each other. The wheat said: 'The field was sown for us,' and the straw said: 'The field was sown for me.' The wheat said to them: 'The hour will come and you will see.' When the time for [storing in] the granary arrived, the owner of the field took the straw and burned it and he scattered the hay; he gathered the wheat up in a pile, and all began to bestow kisses on it. Thus Israel and the nations of the world are judged; some say, ‘The world was created for us,’ while others say, ‘For us [the world was created].’ Israel says: ‘The hour will come, and you will see [in the future]; ‘They shall be scattered, and the wind shall carry them away' (Isaiah 41:16),’ but as for Israel, ‘And you shall rejoice with the Lord, with the Holy One of Israel, shall you be your glory’ (Isaiah 41:16).\n\nTranslation in Spanish:"}], temperature=0.3, max_tokens=477)[0m
2025-09-13 17:20:01,130 - DEBUG - 

2025-09-13 17:20:01,131 - DEBUG - self.optional_params: {}
2025-09-13 17:20:01,132 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:20:01,133 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:20:01,133 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:20:01,134 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 477, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': "Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe wheat and the straw argued with each other. The wheat said: 'The field was sown for us,' and the straw said: 'The field was sown for me.' The wheat said to them: 'The hour will come and you will see.' When the time for [storing in] the granary arrived, the owner of the field took the straw and burned it and he scattered the hay; he gathered the wheat up in a pile, and all began to bestow kisses on it. Thus Israel and the nations of the world are judged; some say, ‘The world was created for us,’ while others say, ‘For us [the world was created].’ Israel says: ‘The hour will come, and you will see [in the future]; ‘They shall be scattered, and the wind shall carry them away' (Isaiah 41:16),’ but as for Israel, ‘And you shall rejoice with the Lord, with the Holy One of Israel, shall you be your glory’ (Isaiah 41:16).\n\nTranslation in Spanish:"}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:20:01,135 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 477}
2025-09-13 17:20:01,137 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 477}
2025-09-13 17:20:01,138 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 477}
2025-09-13 17:20:01,139 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:20:01,140 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:20:01,141 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': "Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe wheat and the straw argued with each other. The wheat said: 'The field was sown for us,' and the straw said: 'The field was sown for me.' The wheat said to them: 'The hour will come and you will see.' When the time for [storing in] the granary arrived, the owner of the field took the straw and burned it and he scattered the hay; he gathered the wheat up in a pile, and all began to bestow kisses on it. Thus Israel and the nations of the world are judged; some say, ‘The world was created for us,’ while others say, ‘For us [the world was created].’ Israel says: ‘The hour will come, and you will see [in the future]; ‘They shall be scattered, and the wind shall carry them away' (Isaiah 41:16),’ but as for Israel, ‘And you shall rejoice with the Lord, with the Holy One of Israel, shall you be your glory’ (Isaiah 41:16).\n\nTranslation in Spanish:"}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 477}}'
[0m

2025-09-13 17:20:01,142 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:20:01,142 - DEBUG - send_request_headers.complete
2025-09-13 17:20:01,143 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:20:01,143 - DEBUG - send_request_body.complete
2025-09-13 17:20:01,143 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:20:01,461 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-09-13 17:20:01,462 - DEBUG - response_closed.started
2025-09-13 17:20:01,462 - DEBUG - response_closed.complete
2025-09-13 17:20:01,477 - DEBUG - Using proactor: IocpProactor
2025-09-13 17:21:23,789 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:21:23,790 - INFO - Language: English -> Spanish
2025-09-13 17:21:23,790 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:21:23,790 - INFO - Step 1: Extracting document content...
2025-09-13 17:21:24,116 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:21:24,117 - INFO - Step 2: Translating content...
2025-09-13 17:21:24,117 - INFO - Translating 129 paragraphs...
2025-09-13 17:21:24,117 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:21:24,122 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:26,415 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:26,421 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:26,423 - INFO - Progress: 2/131 - Translating paragraph 1
2025-09-13 17:21:26,424 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:27,108 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:27,114 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:27,115 - INFO - Progress: 3/131 - Translating paragraph 2
2025-09-13 17:21:27,118 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:28,496 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:28,499 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:28,500 - INFO - Progress: 4/131 - Translating paragraph 4
2025-09-13 17:21:28,501 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:29,067 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:29,068 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:29,069 - INFO - Progress: 5/131 - Translating paragraph 5
2025-09-13 17:21:29,070 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:31,580 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:31,583 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:31,585 - INFO - Progress: 6/131 - Translating paragraph 6
2025-09-13 17:21:31,589 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:32,334 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:32,336 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:32,337 - INFO - Progress: 7/131 - Translating paragraph 7
2025-09-13 17:21:32,340 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:35,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:35,599 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:35,601 - INFO - Progress: 8/131 - Translating paragraph 8
2025-09-13 17:21:35,602 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:37,541 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:37,544 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:37,545 - INFO - Progress: 9/131 - Translating paragraph 10
2025-09-13 17:21:37,547 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:39,709 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:21:39,711 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:21:39,713 - INFO - Progress: 10/131 - Translating paragraph 11
2025-09-13 17:21:39,717 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:40,050 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:21:40,082 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "19s"
      }
    ]
  }
}

2025-09-13 17:21:40,083 - ERROR - Failed text: The wheat and the straw argued with each other. The wheat said: 'The field was sown for us,' and the...
2025-09-13 17:21:40,083 - INFO - Progress: 11/131 - Translating paragraph 12
2025-09-13 17:21:40,087 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:54,735 - DEBUG - Verbose logging enabled
2025-09-13 17:21:54,737 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:21:54,737 - INFO - Language: English -> Spanish
2025-09-13 17:21:54,738 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:21:54,738 - INFO - Step 1: Extracting document content...
2025-09-13 17:21:55,087 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:21:55,088 - INFO - Step 2: Translating content...
2025-09-13 17:21:55,089 - INFO - Translating 129 paragraphs...
2025-09-13 17:21:55,089 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:21:55,090 - DEBUG - 

2025-09-13 17:21:55,090 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:21:55,091 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=6)[0m
2025-09-13 17:21:55,091 - DEBUG - 

2025-09-13 17:21:55,092 - DEBUG - self.optional_params: {}
2025-09-13 17:21:55,092 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:21:55,100 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:21:55,101 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:55,101 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 6, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:21:55,102 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:21:55,102 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 6}
2025-09-13 17:21:55,102 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:21:55,103 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:55,105 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:55,107 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 6}}'
[0m

2025-09-13 17:21:55,497 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-09-13 17:21:55,543 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019C433442D0>
2025-09-13 17:21:55,544 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000019C432E8A70> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-09-13 17:21:55,593 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019C4329E8B0>
2025-09-13 17:21:55,594 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:21:55,595 - DEBUG - send_request_headers.complete
2025-09-13 17:21:55,595 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:21:55,596 - DEBUG - send_request_body.complete
2025-09-13 17:21:55,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:21:57,222 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:51:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1581'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:21:57,224 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:21:57,225 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:21:57,226 - DEBUG - receive_response_body.complete
2025-09-13 17:21:57,227 - DEBUG - response_closed.started
2025-09-13 17:21:57,227 - DEBUG - response_closed.complete
2025-09-13 17:21:57,231 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:21:57,247 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:21:57,254 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "2s"
      }
    ]
  }
}

2025-09-13 17:21:57,254 - ERROR - Failed text: Chapter 2...
2025-09-13 17:21:57,255 - INFO - Progress: 2/131 - Translating paragraph 1
2025-09-13 17:21:57,255 - DEBUG - 

2025-09-13 17:21:57,256 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:21:57,256 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=6)[0m
2025-09-13 17:21:57,256 - DEBUG - 

2025-09-13 17:21:57,256 - DEBUG - self.optional_params: {}
2025-09-13 17:21:57,257 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:21:57,258 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:21:57,258 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:57,259 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 6, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:21:57,259 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:21:57,260 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 6}
2025-09-13 17:21:57,260 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:21:57,261 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:57,261 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:57,262 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nVerses 64-92\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 6}}'
[0m

2025-09-13 17:21:57,263 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:21:57,263 - DEBUG - send_request_headers.complete
2025-09-13 17:21:57,263 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:21:57,264 - DEBUG - send_request_body.complete
2025-09-13 17:21:57,264 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:21:57,599 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:51:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=289'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:21:57,601 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:21:57,602 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:21:57,603 - DEBUG - receive_response_body.complete
2025-09-13 17:21:57,604 - DEBUG - response_closed.started
2025-09-13 17:21:57,605 - DEBUG - response_closed.complete
2025-09-13 17:21:57,608 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:21:57,629 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:21:57,636 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "2s"
      }
    ]
  }
}

2025-09-13 17:21:57,637 - ERROR - Failed text: Verses 64-92...
2025-09-13 17:21:57,637 - INFO - Progress: 3/131 - Translating paragraph 2
2025-09-13 17:21:57,638 - DEBUG - 

2025-09-13 17:21:57,638 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:21:57,639 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=30)[0m
2025-09-13 17:21:57,641 - DEBUG - 

2025-09-13 17:21:57,642 - DEBUG - self.optional_params: {}
2025-09-13 17:21:57,642 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:21:57,643 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:21:57,644 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:57,645 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 30, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:21:57,645 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 30}
2025-09-13 17:21:57,646 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 30}
2025-09-13 17:21:57,646 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 30}
2025-09-13 17:21:57,647 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:57,647 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:57,648 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe Second Vision: A Vision of the End of Days\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 30}}'
[0m

2025-09-13 17:21:57,651 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:21:57,652 - DEBUG - send_request_headers.complete
2025-09-13 17:21:57,653 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:21:57,653 - DEBUG - send_request_body.complete
2025-09-13 17:21:57,654 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:21:58,893 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:51:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1195'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:21:58,895 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:21:58,896 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:21:58,899 - DEBUG - receive_response_body.complete
2025-09-13 17:21:58,899 - DEBUG - response_closed.started
2025-09-13 17:21:58,900 - DEBUG - response_closed.complete
2025-09-13 17:21:58,903 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:21:58,921 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:21:58,930 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-09-13 17:21:58,932 - ERROR - Failed text: The Second Vision: A Vision of the End of Days...
2025-09-13 17:21:58,933 - INFO - Progress: 4/131 - Translating paragraph 4
2025-09-13 17:21:58,933 - DEBUG - 

2025-09-13 17:21:58,935 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:21:58,936 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=12)[0m
2025-09-13 17:21:58,937 - DEBUG - 

2025-09-13 17:21:58,939 - DEBUG - self.optional_params: {}
2025-09-13 17:21:58,940 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:21:58,941 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:21:58,942 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:58,942 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 12, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:21:58,943 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:21:58,944 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 12}
2025-09-13 17:21:58,944 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:21:58,945 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:58,945 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:58,947 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nSynopsis of Chapter 2:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 12}}'
[0m

2025-09-13 17:21:58,948 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:21:58,950 - DEBUG - send_request_headers.complete
2025-09-13 17:21:58,951 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:21:58,951 - DEBUG - send_request_body.complete
2025-09-13 17:21:58,952 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:21:59,277 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:51:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=282'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:21:59,278 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:21:59,279 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:21:59,280 - DEBUG - receive_response_body.complete
2025-09-13 17:21:59,281 - DEBUG - response_closed.started
2025-09-13 17:21:59,282 - DEBUG - response_closed.complete
2025-09-13 17:21:59,287 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:21:59,300 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:21:59,307 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "0s"
      }
    ]
  }
}

2025-09-13 17:21:59,308 - ERROR - Failed text: Synopsis of Chapter 2:...
2025-09-13 17:21:59,308 - INFO - Progress: 5/131 - Translating paragraph 5
2025-09-13 17:21:59,309 - DEBUG - 

2025-09-13 17:21:59,310 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:21:59,310 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=438)[0m
2025-09-13 17:21:59,311 - DEBUG - 

2025-09-13 17:21:59,311 - DEBUG - self.optional_params: {}
2025-09-13 17:21:59,312 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:21:59,313 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:21:59,313 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:21:59,314 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 438, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:21:59,315 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 438}
2025-09-13 17:21:59,316 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 438}
2025-09-13 17:21:59,316 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 438}
2025-09-13 17:21:59,317 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:59,318 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:21:59,318 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nGad, in his vision, saw what would occur to the people of Israel and to the nations of the world at the end of days. The people of Israel would be gathered to their land, and neither curse nor impurity would be with them. All the nations would fulfill the Torah and ‘everyone would speak in the language of the Jews, the language of holiness.’ After the consolation would come the vengeance – the Lord would fight the wars of Israel. The Lord would first punish Edom, as well as those who claimed that He had expelled His people.  Afterwards, the Lord would make an end of Spain, France, Ashkenaz and Germany. Michael, the great prince, would overcome Samael, the prince of the world, and the Lord would save Israel for having done ‘all that I have commanded you in the law of Moses, My servant’.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 438}}'
[0m

2025-09-13 17:21:59,320 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:21:59,320 - DEBUG - send_request_headers.complete
2025-09-13 17:21:59,320 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:21:59,321 - DEBUG - send_request_body.complete
2025-09-13 17:21:59,321 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:22:00,603 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:52:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1237'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:22:00,605 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:22:00,606 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:22:00,607 - DEBUG - receive_response_body.complete
2025-09-13 17:22:00,608 - DEBUG - response_closed.started
2025-09-13 17:22:00,609 - DEBUG - response_closed.complete
2025-09-13 17:22:00,612 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:22:00,626 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:22:00,634 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "59s"
      }
    ]
  }
}

2025-09-13 17:22:00,635 - ERROR - Failed text: Gad, in his vision, saw what would occur to the people of Israel and to the nations of the world at ...
2025-09-13 17:22:00,635 - INFO - Progress: 6/131 - Translating paragraph 6
2025-09-13 17:22:00,635 - DEBUG - 

2025-09-13 17:22:00,636 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:22:00,636 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=12)[0m
2025-09-13 17:22:00,636 - DEBUG - 

2025-09-13 17:22:00,637 - DEBUG - self.optional_params: {}
2025-09-13 17:22:00,638 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:22:00,638 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:22:00,639 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:22:00,640 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 12, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:22:00,641 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:22:00,642 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 12}
2025-09-13 17:22:00,643 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 12}
2025-09-13 17:22:00,644 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:00,645 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:00,646 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIntroduction to Chapter 2:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 12}}'
[0m

2025-09-13 17:22:00,648 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:22:00,649 - DEBUG - send_request_headers.complete
2025-09-13 17:22:00,650 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:22:00,650 - DEBUG - send_request_body.complete
2025-09-13 17:22:00,651 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:22:00,978 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:52:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=283'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:22:00,979 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:22:00,980 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:22:00,981 - DEBUG - receive_response_body.complete
2025-09-13 17:22:00,982 - DEBUG - response_closed.started
2025-09-13 17:22:00,983 - DEBUG - response_closed.complete
2025-09-13 17:22:00,986 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:22:00,999 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:22:01,009 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "58s"
      }
    ]
  }
}

2025-09-13 17:22:01,010 - ERROR - Failed text: Introduction to Chapter 2:...
2025-09-13 17:22:01,011 - INFO - Progress: 7/131 - Translating paragraph 7
2025-09-13 17:22:01,012 - DEBUG - 

2025-09-13 17:22:01,013 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:22:01,014 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=648)[0m
2025-09-13 17:22:01,015 - DEBUG - 

2025-09-13 17:22:01,017 - DEBUG - self.optional_params: {}
2025-09-13 17:22:01,018 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:22:01,021 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:22:01,023 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:22:01,025 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 648, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:22:01,027 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 648}
2025-09-13 17:22:01,028 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 648}
2025-09-13 17:22:01,029 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 648}
2025-09-13 17:22:01,030 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:01,031 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:01,031 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and this is an eschatological vision, which, in terms of its genre, belongs simultaneously to both apocalyptic and prophetic literature. On the one hand, the seer opens with the words, ‘The vision of the Lord was unto me, saying’ and this seems to be a continuation of the vision from the previous chapter. On the other hand, the seer, as a prophet, is commanded by the Lord to perform acts of a symbolic nature, and, moreover, to address his assembled listeners with the words, ‘Thus saith the Lord.’ At the outset of his speech, the seer is to turn to ‘the four corners of the earth,’ a metaphorical phrase that does not necessarily call attention to the speaker’s audience. However, later on, the seer addresses his listeners in the present tense (72): ‘Rejoice and be glad, remnant of Judah and banished of Israel,’ and he goes on to address the people of Israel in the second person (73-77; 91-92), and from here we see that the seer spoke his words, as a prophet, to the people of Israel. It seems that this chapter supports the argument of scholars who see apocalyptic literature as stemming from prophetic literature.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 648}}'
[0m

2025-09-13 17:22:01,034 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:22:01,035 - DEBUG - send_request_headers.complete
2025-09-13 17:22:01,035 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:22:01,036 - DEBUG - send_request_body.complete
2025-09-13 17:22:01,037 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:22:02,283 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:52:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1202'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:22:02,286 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:22:02,287 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:22:02,289 - DEBUG - receive_response_body.complete
2025-09-13 17:22:02,289 - DEBUG - response_closed.started
2025-09-13 17:22:02,290 - DEBUG - response_closed.complete
2025-09-13 17:22:02,293 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:22:02,310 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:22:02,317 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "57s"
      }
    ]
  }
}

2025-09-13 17:22:02,318 - ERROR - Failed text: Chapter 2 is a vision that describes what will happen at the end of days, that is, ‘end times’ and t...
2025-09-13 17:22:02,318 - INFO - Progress: 8/131 - Translating paragraph 8
2025-09-13 17:22:02,319 - DEBUG - 

2025-09-13 17:22:02,319 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:22:02,320 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=456)[0m
2025-09-13 17:22:02,321 - DEBUG - 

2025-09-13 17:22:02,322 - DEBUG - self.optional_params: {}
2025-09-13 17:22:02,322 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:22:02,323 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:22:02,324 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:22:02,325 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 456, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:22:02,326 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 456}
2025-09-13 17:22:02,327 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 456}
2025-09-13 17:22:02,328 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 456}
2025-09-13 17:22:02,328 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:02,329 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:02,330 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nIn several ways, as a pair of chapters that complement each other, the second vision completes the vision in the first chapter. This phenomenon, according to which a certain idea appears in the form of a pair of chapters, is well known in apocalyptic literature, especially in the Book of Daniel. At the same time, the difference between the two visions is quite clear: the first vision symbolically describes a heavenly revelation of what will happen in the future. In contrast, the vision in the second chapter describes the end of days not symbolically, but in a real way, even though the language is symbolic. In addition, the second vision involves the attribute of divine justice, and deals with the punishment of the nations of the world in the future, and thus the second vision is similar to some of the prophetic Scriptures, and the use of biblical language reinforces this similarity.\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 456}}'
[0m

2025-09-13 17:22:02,332 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:22:02,333 - DEBUG - send_request_headers.complete
2025-09-13 17:22:02,333 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:22:02,334 - DEBUG - send_request_body.complete
2025-09-13 17:22:02,334 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:22:02,662 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sat, 13 Sep 2025 11:52:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=283'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-09-13 17:22:02,664 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:22:02,665 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-13 17:22:02,668 - DEBUG - receive_response_body.complete
2025-09-13 17:22:02,668 - DEBUG - response_closed.started
2025-09-13 17:22:02,669 - DEBUG - response_closed.complete
2025-09-13 17:22:02,673 - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-09-13 17:22:02,689 - DEBUG - Logging Details LiteLLM-Failure Call: []
2025-09-13 17:22:02,697 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "57s"
      }
    ]
  }
}

2025-09-13 17:22:02,697 - ERROR - Failed text: In several ways, as a pair of chapters that complement each other, the second vision completes the v...
2025-09-13 17:22:02,698 - INFO - Progress: 9/131 - Translating paragraph 10
2025-09-13 17:22:02,699 - DEBUG - 

2025-09-13 17:22:02,699 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:22:02,700 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=564)[0m
2025-09-13 17:22:02,702 - DEBUG - 

2025-09-13 17:22:02,703 - DEBUG - self.optional_params: {}
2025-09-13 17:22:02,703 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:22:02,705 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:22:02,706 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:22:02,707 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 564, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:22:02,708 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 564}
2025-09-13 17:22:02,708 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 564}
2025-09-13 17:22:02,709 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 564}
2025-09-13 17:22:02,709 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:02,710 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:22:02,710 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nThe first matter to emerge in the end of days is to be the gathering of Israel to their land, an idea that is well established in Scripture. The seer describes the return of Israel with the help of two sets of metaphors. According to the first, God will bird-whistle and gather His people together like a bird that whistles and gathers its chicks. According to the second, Israel is like a seed of grain, and the Land of Israel is likened to a granary, and at the end of days, which according to the seer will be ‘yet a little while,’ God will gather His seed into His granary.  The idea that Israel was likened to a seed appears already above (54: ‘For they are a true seed’), but now the matter is much more developed, and the metaphor clarifies the status of Israel. Israel is likened to wheat-seed (even if the word ‘wheat’ is not mentioned), while the other nations are likened to other seeds, which are of lower value than wheat, such as lentils, barley, etc. A similar idea also appears in the midrashic literature:\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 564}}'
[0m

2025-09-13 17:22:02,711 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:22:02,712 - DEBUG - send_request_headers.complete
2025-09-13 17:22:02,712 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:22:02,712 - DEBUG - send_request_body.complete
2025-09-13 17:22:02,712 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:22:03,968 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-09-13 17:22:03,969 - DEBUG - response_closed.started
2025-09-13 17:22:03,969 - DEBUG - response_closed.complete
2025-09-13 17:22:03,990 - DEBUG - Using proactor: IocpProactor
2025-09-13 17:23:28,708 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:23:28,708 - INFO - Language: English -> Spanish
2025-09-13 17:23:28,709 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:23:28,709 - INFO - Step 1: Extracting document content...
2025-09-13 17:23:29,251 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:23:29,252 - INFO - Step 2: Translating content...
2025-09-13 17:23:29,253 - INFO - Translating 129 paragraphs...
2025-09-13 17:23:29,254 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:23:29,279 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:32,429 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:23:32,435 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:23:32,443 - INFO - Progress: 2/131 - Translating paragraph 1
2025-09-13 17:23:32,447 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:33,002 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 200 OK"
2025-09-13 17:23:33,017 - INFO - Wrapper: Completed Call, calling success_handler
2025-09-13 17:23:33,023 - INFO - Progress: 3/131 - Translating paragraph 2
2025-09-13 17:23:33,027 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:34,090 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:23:34,143 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "location": "global",
              "model": "gemini-1.5-flash"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

2025-09-13 17:23:34,144 - ERROR - Failed text: The Second Vision: A Vision of the End of Days...
2025-09-13 17:23:34,144 - INFO - Progress: 4/131 - Translating paragraph 4
2025-09-13 17:23:34,146 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:34,632 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyBHXtv039C4hMHaJGhtOD9fbTCyclcJcHg "HTTP/1.1 429 Too Many Requests"
2025-09-13 17:23:34,664 - ERROR - Translation error: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {
  "error": {
    "code": 429,
    "message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
    "status": "RESOURCE_EXHAUSTED",
    "details": [
      {
        "@type": "type.googleapis.com/google.rpc.QuotaFailure",
        "violations": [
          {
            "quotaMetric": "generativelanguage.googleapis.com/generate_content_free_tier_requests",
            "quotaId": "GenerateRequestsPerDayPerProjectPerModel-FreeTier",
            "quotaDimensions": {
              "model": "gemini-1.5-flash",
              "location": "global"
            },
            "quotaValue": "50"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.Help",
        "links": [
          {
            "description": "Learn more about Gemini API quotas",
            "url": "https://ai.google.dev/gemini-api/docs/rate-limits"
          }
        ]
      },
      {
        "@type": "type.googleapis.com/google.rpc.RetryInfo",
        "retryDelay": "25s"
      }
    ]
  }
}

2025-09-13 17:23:34,667 - ERROR - Failed text: Synopsis of Chapter 2:...
2025-09-13 17:23:34,668 - INFO - Progress: 5/131 - Translating paragraph 5
2025-09-13 17:23:34,670 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:47,276 - DEBUG - Verbose logging enabled
2025-09-13 17:23:47,278 - INFO - Starting translation: academic_paper.docx -> academic_paper_translated_spanish.docx
2025-09-13 17:23:47,278 - INFO - Language: English -> Spanish
2025-09-13 17:23:47,280 - INFO - Model: gemini/gemini-1.5-flash
2025-09-13 17:23:47,281 - INFO - Step 1: Extracting document content...
2025-09-13 17:23:48,417 - INFO - Document extracted: 129 paragraphs, 2 tables, 11307 words
2025-09-13 17:23:48,418 - INFO - Step 2: Translating content...
2025-09-13 17:23:48,419 - INFO - Translating 129 paragraphs...
2025-09-13 17:23:48,420 - INFO - Progress: 1/131 - Translating paragraph 0
2025-09-13 17:23:48,421 - DEBUG - 

2025-09-13 17:23:48,422 - DEBUG - [92mRequest to litellm:[0m
2025-09-13 17:23:48,423 - DEBUG - [92mlitellm.completion(model='gemini/gemini-1.5-flash', messages=[{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], temperature=0.3, max_tokens=6)[0m
2025-09-13 17:23:48,426 - DEBUG - 

2025-09-13 17:23:48,427 - DEBUG - self.optional_params: {}
2025-09-13 17:23:48,430 - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-09-13 17:23:48,494 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'vertex_ai/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-flash', 'custom_llm_provider': 'vertex_ai'}
2025-09-13 17:23:48,500 - INFO - 
LiteLLM completion() model= gemini-1.5-flash; provider = gemini
2025-09-13 17:23:48,503 - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-flash', 'functions': None, 'function_call': None, 'temperature': 0.3, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': 6, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}], 'thinking': None, 'web_search_options': None}
2025-09-13 17:23:48,506 - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:23:48,509 - DEBUG - Final returned optional params: {'temperature': 0.3, 'max_output_tokens': 6}
2025-09-13 17:23:48,512 - DEBUG - self.optional_params: {'temperature': 0.3, 'max_tokens': 6}
2025-09-13 17:23:48,517 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:23:48,534 - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-flash', 'combined_model_name': 'gemini/gemini-1.5-flash', 'stripped_model_name': 'gemini-1.5-flash', 'combined_stripped_model_name': 'gemini/gemini-1.5-flash', 'custom_llm_provider': 'gemini'}
2025-09-13 17:23:48,536 - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=*****JcHg \
-H 'Content-Type: application/json' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': 'Translate the following English text to Spanish.\n\nIMPORTANT RULES:\n1. Maintain academic tone and precision\n2. Preserve technical terminology accuracy  \n3. Keep the same meaning and context\n4. Return ONLY the translated text, no explanations\n5. Do not add any additional text or notes\n\nThis is part of an academic document.\n\nText to translate:\nChapter 2\n\nTranslation in Spanish:'}]}], 'generationConfig': {'temperature': 0.3, 'max_output_tokens': 6}}'
[0m

2025-09-13 17:23:49,998 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-09-13 17:23:50,043 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018E70EF42D0>
2025-09-13 17:23:50,044 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018E70E98A70> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-09-13 17:23:50,096 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018E70E4E8B0>
2025-09-13 17:23:50,097 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-13 17:23:50,100 - DEBUG - send_request_headers.complete
2025-09-13 17:23:50,101 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-13 17:23:50,104 - DEBUG - send_request_body.complete
2025-09-13 17:23:50,105 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-13 17:23:51,700 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-09-13 17:23:51,701 - DEBUG - response_closed.started
2025-09-13 17:23:51,702 - DEBUG - response_closed.complete
2025-09-13 17:23:51,756 - DEBUG - Using proactor: IocpProactor
